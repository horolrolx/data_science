{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\Song\\AppData\\Local\\Temp\\ipykernel_14648\\1755282833.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('imdb.tsv', delimiter = \"\\\\t\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [(``, ``), (Watching, JJ), (Time, NN), (Chaser...\n",
       "1    [(I, PRP), (saw, VBD), (this, DT), (film, NN),...\n",
       "2    [(Minor, JJ), (Spoilers, NNS), (In, IN), (New,...\n",
       "3    [(I, PRP), (went, VBD), (to, TO), (see, VB), (...\n",
       "4    [(``, ``), (Yes, UH), (,, ,), (I, PRP), (agree...\n",
       "5    [(``, ``), (Jennifer, NNP), (Ehle, NNP), (was,...\n",
       "6    [(Amy, NNP), (Poehler, NNP), (is, VBZ), (a, DT...\n",
       "7    [(``, ``), (A, DT), (plane, NN), (carrying, VB...\n",
       "8    [(A, DT), (well, NN), (made, VBN), (,, ,), (gr...\n",
       "9    [(``, ``), (Incredibly, RB), (dumb, JJ), (and,...\n",
       "Name: pos_tagged_tokens, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from preprocess import pos_tagger\n",
    "\n",
    "df = pd.read_csv('imdb.tsv', delimiter = \"\\\\t\")\n",
    "\n",
    "df['sent_tokens'] = df['review'].apply(sent_tokenize)\n",
    "df['pos_tagged_tokens'] = df['sent_tokens'].apply(pos_tagger)\n",
    "\n",
    "df['pos_tagged_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>pos_tagged_tokens</th>\n",
       "      <th>swn_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Watching Time Chasers, it obvious that it was ...</td>\n",
       "      <td>[Watching Time Chasers, it obvious that it was...</td>\n",
       "      <td>[(Watching, VBG), (Time, NNP), (Chasers, NNPS)...</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I saw this film about 20 years ago and remembe...</td>\n",
       "      <td>[I saw this film about 20 years ago and rememb...</td>\n",
       "      <td>[(I, PRP), (saw, VBD), (this, DT), (film, NN),...</td>\n",
       "      <td>-1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Minor Spoilers In New York, Joan Barnard (Elvi...</td>\n",
       "      <td>[Minor Spoilers In New York, Joan Barnard (Elv...</td>\n",
       "      <td>[(Minor, JJ), (Spoilers, NNS), (In, IN), (New,...</td>\n",
       "      <td>-3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I went to see this film with a great deal of e...</td>\n",
       "      <td>[I went to see this film with a great deal of ...</td>\n",
       "      <td>[(I, PRP), (went, VBD), (to, TO), (see, VB), (...</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes, I agree with everyone on this site this m...</td>\n",
       "      <td>[Yes, I agree with everyone on this site this ...</td>\n",
       "      <td>[(Yes, UH), (,, ,), (I, PRP), (agree, VBP), (w...</td>\n",
       "      <td>2.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jennifer Ehle was sparkling in \\\"Pride and Pre...</td>\n",
       "      <td>[Jennifer Ehle was sparkling in \\\"Pride and Pr...</td>\n",
       "      <td>[(Jennifer, NNP), (Ehle, NNP), (was, VBD), (sp...</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Amy Poehler is a terrific comedian on Saturday...</td>\n",
       "      <td>[Amy Poehler is a terrific comedian on Saturda...</td>\n",
       "      <td>[(Amy, NNP), (Poehler, NNP), (is, VBZ), (a, DT...</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A plane carrying employees of a large biotech ...</td>\n",
       "      <td>[A plane carrying employees of a large biotech...</td>\n",
       "      <td>[(A, DT), (plane, NN), (carrying, VBG), (emplo...</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A well made, gritty science fiction movie, it ...</td>\n",
       "      <td>[A well made, gritty science fiction movie, it...</td>\n",
       "      <td>[(A, DT), (well, NN), (made, VBN), (,, ,), (gr...</td>\n",
       "      <td>4.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Incredibly dumb and utterly predictable story ...</td>\n",
       "      <td>[Incredibly dumb and utterly predictable story...</td>\n",
       "      <td>[(Incredibly, RB), (dumb, JJ), (and, CC), (utt...</td>\n",
       "      <td>-1.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  \\\n",
       "0           0  Watching Time Chasers, it obvious that it was ...   \n",
       "1           1  I saw this film about 20 years ago and remembe...   \n",
       "2           2  Minor Spoilers In New York, Joan Barnard (Elvi...   \n",
       "3           3  I went to see this film with a great deal of e...   \n",
       "4           4  Yes, I agree with everyone on this site this m...   \n",
       "5           5  Jennifer Ehle was sparkling in \\\"Pride and Pre...   \n",
       "6           6  Amy Poehler is a terrific comedian on Saturday...   \n",
       "7           7  A plane carrying employees of a large biotech ...   \n",
       "8           8  A well made, gritty science fiction movie, it ...   \n",
       "9           9  Incredibly dumb and utterly predictable story ...   \n",
       "\n",
       "                                         sent_tokens  \\\n",
       "0  [Watching Time Chasers, it obvious that it was...   \n",
       "1  [I saw this film about 20 years ago and rememb...   \n",
       "2  [Minor Spoilers In New York, Joan Barnard (Elv...   \n",
       "3  [I went to see this film with a great deal of ...   \n",
       "4  [Yes, I agree with everyone on this site this ...   \n",
       "5  [Jennifer Ehle was sparkling in \\\"Pride and Pr...   \n",
       "6  [Amy Poehler is a terrific comedian on Saturda...   \n",
       "7  [A plane carrying employees of a large biotech...   \n",
       "8  [A well made, gritty science fiction movie, it...   \n",
       "9  [Incredibly dumb and utterly predictable story...   \n",
       "\n",
       "                                   pos_tagged_tokens  swn_sentiment  \n",
       "0  [(Watching, VBG), (Time, NNP), (Chasers, NNPS)...         -0.250  \n",
       "1  [(I, PRP), (saw, VBD), (this, DT), (film, NN),...         -1.500  \n",
       "2  [(Minor, JJ), (Spoilers, NNS), (In, IN), (New,...         -3.000  \n",
       "3  [(I, PRP), (went, VBD), (to, TO), (see, VB), (...         -0.250  \n",
       "4  [(Yes, UH), (,, ,), (I, PRP), (agree, VBP), (w...          2.625  \n",
       "5  [(Jennifer, NNP), (Ehle, NNP), (was, VBD), (sp...          7.000  \n",
       "6  [(Amy, NNP), (Poehler, NNP), (is, VBZ), (a, DT...          0.750  \n",
       "7  [(A, DT), (plane, NN), (carrying, VBG), (emplo...          9.000  \n",
       "8  [(A, DT), (well, NN), (made, VBN), (,, ,), (gr...          4.500  \n",
       "9  [(Incredibly, RB), (dumb, JJ), (and, CC), (utt...         -1.625  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from preprocess import pos_tagger\n",
    "from preprocess import penn_to_wn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv('imdb.tsv', delimiter = \"\\t\")\n",
    "df['sent_tokens'] = df['review'].apply(sent_tokenize)\n",
    "df['pos_tagged_tokens'] = df['sent_tokens'].apply(pos_tagger)\n",
    "\n",
    "def swn_polarity(pos_tagged_sents):\n",
    "    # 감성 지수 초기화\n",
    "    sentiment_score = 0\n",
    "\n",
    "    for word, tag in pos_tagged_sents:\n",
    "        # NLTK 기반 품사 태깅을 WordNet기반 품사 태그로 변환\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV, wn.VERB):\n",
    "            continue\n",
    "            \n",
    "        # 단어와 품사 태그를 기반으로 Synsets 구하기\n",
    "        synsets = wn.synsets(word, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        \n",
    "        # Synsets의 첫 번째 요소의 이름으로 단일 SentiSynset 구하기\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        \n",
    "        # SentiSynset을 통해 단어의 감성 지수 구하기\n",
    "        word_senti_score = swn_synset.pos_score() - swn_synset.neg_score()\n",
    "\n",
    "        # 각 단어의 감성 지수를 더하여 코퍼스의 감성 지수 값 계산해 반환하기\n",
    "        sentiment_score += word_senti_score\n",
    "    return sentiment_score\n",
    "\n",
    "# 데이터 프레임에 적용 \n",
    "df['swn_sentiment'] = df['pos_tagged_tokens'].apply(swn_polarity)\n",
    "\n",
    "# 테스트 코드\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
