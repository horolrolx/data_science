{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from preprocess import clean_by_freq\n",
    "from preprocess import clean_by_len\n",
    "from preprocess import clean_by_stopwords\n",
    "from preprocess import stemming_by_porter\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Watching Time Chasers, it obvious that it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I saw this film about 20 years ago and remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Minor Spoilers In New York, Joan Barnard (Elvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I went to see this film with a great deal of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes, I agree with everyone on this site this m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jennifer Ehle was sparkling in \\\"Pride and Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Amy Poehler is a terrific comedian on Saturday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A plane carrying employees of a large biotech ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A well made, gritty science fiction movie, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Incredibly dumb and utterly predictable story ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review\n",
       "0           0  Watching Time Chasers, it obvious that it was ...\n",
       "1           1  I saw this film about 20 years ago and remembe...\n",
       "2           2  Minor Spoilers In New York, Joan Barnard (Elvi...\n",
       "3           3  I went to see this film with a great deal of e...\n",
       "4           4  Yes, I agree with everyone on this site this m...\n",
       "5           5  Jennifer Ehle was sparkling in \\\"Pride and Pre...\n",
       "6           6  Amy Poehler is a terrific comedian on Saturday...\n",
       "7           7  A plane carrying employees of a large biotech ...\n",
       "8           8  A well made, gritty science fiction movie, it ...\n",
       "9           9  Incredibly dumb and utterly predictable story ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('imdb.tsv', delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watching time chasers, it obvious that it was made by a bunch of friends. maybe they were sitting around one day in film school and said, \\\"hey, let's pool our money together and make a really bad movie!\\\" or something like that. what ever they said, they still ended up making a really bad movie--dull story, bad script, lame acting, poor cinematography, bottom of the barrel stock music, etc. all corners were cut, except the one that would have prevented this film's release. life's like that.\n"
     ]
    }
   ],
   "source": [
    "print(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_tokens'] = df['review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['watching', 'time', 'chasers', ',', 'it', 'obvious', 'that', 'it', 'was', 'made', 'by', 'a', 'bunch', 'of', 'friends', '.', 'maybe', 'they', 'were', 'sitting', 'around', 'one', 'day', 'in', 'film', 'school', 'and', 'said', ',', '\\\\', \"''\", 'hey', ',', 'let', \"'s\", 'pool', 'our', 'money', 'together', 'and', 'make', 'a', 'really', 'bad', 'movie', '!', '\\\\', \"''\", 'or', 'something', 'like', 'that', '.', 'what', 'ever', 'they', 'said', ',', 'they', 'still', 'ended', 'up', 'making', 'a', 'really', 'bad', 'movie', '--', 'dull', 'story', ',', 'bad', 'script', ',', 'lame', 'acting', ',', 'poor', 'cinematography', ',', 'bottom', 'of', 'the', 'barrel', 'stock', 'music', ',', 'etc', '.', 'all', 'corners', 'were', 'cut', ',', 'except', 'the', 'one', 'that', 'would', 'have', 'prevented', 'this', 'film', \"'s\", 'release', '.', 'life', \"'s\", 'like', 'that', '.']\n"
     ]
    }
   ],
   "source": [
    "print(df['word_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# .py 모듈 수정 시 자동 리로드\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocess import clean_by_freq\n",
    "from preprocess import clean_by_len\n",
    "from preprocess import clean_by_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "df['cleaned_tokens'] = df['word_tokens'].apply(lambda x: clean_by_freq(x, 1))\n",
    "df['cleaned_tokens'] = df['cleaned_tokens'].apply(lambda x: clean_by_len(x, 2))\n",
    "df['cleaned_tokens'] = df['cleaned_tokens'].apply(lambda x: clean_by_stopwords(x, stopwords_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'film', 'said', 'really', 'bad', 'movie', 'like', 'said', 'really', 'bad', 'movie', 'bad', 'one', 'film', 'like']\n"
     ]
    }
   ],
   "source": [
    "print(df['cleaned_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import stemming_by_porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_tokens'] = df['cleaned_tokens'].apply(stemming_by_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'film', 'said', 'realli', 'bad', 'movi', 'like', 'said', 'realli', 'bad', 'movi', 'bad', 'one', 'film', 'like']\n"
     ]
    }
   ],
   "source": [
    "print(df['stemmed_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Song\\AppData\\Local\\Temp\\ipykernel_15304\\34434989.py:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('imdb.tsv', delimiter='\\\\t')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from preprocess import clean_by_freq\n",
    "from preprocess import clean_by_len\n",
    "from preprocess import clean_by_stopwords\n",
    "from preprocess import stemming_by_porter\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('imdb.tsv', delimiter='\\\\t')\n",
    "\n",
    "# 대소문자 통합\n",
    "df['review'] = df['review'].str.lower()\n",
    "\n",
    "# 단어 토큰화\n",
    "df['word_tokens'] = df['review'].apply(word_tokenize)\n",
    "\n",
    "# 정제\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "df['cleaned_tokens'] = df['word_tokens'].apply(lambda x: clean_by_freq(x, 1))\n",
    "df['cleaned_tokens'] = df['cleaned_tokens'].apply(lambda x: clean_by_len(x, 2))\n",
    "df['cleaned_tokens'] = df['cleaned_tokens'].apply(lambda x: clean_by_stopwords(x, stopwords_set))\n",
    "\n",
    "# 어간 추출\n",
    "df['stemmed_tokens'] = df['cleaned_tokens'].apply(stemming_by_porter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
